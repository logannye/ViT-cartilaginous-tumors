{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmK4Q94V7PSO+i33MauB9s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMMPRtIRv7t0","executionInfo":{"status":"ok","timestamp":1674162080229,"user_tz":300,"elapsed":22342,"user":{"displayName":"Logan Nye","userId":"10840817294754419157"}},"outputId":"8a730891-32c3-46f0-877d-d55ea16982a2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","\n","zip_path = '/content/Enchondroma vs Grade I Chondrosarcoma.dataset.zip.zip'\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall()"],"metadata":{"id":"6Ov_KYvt2mQy","executionInfo":{"status":"ok","timestamp":1674162376884,"user_tz":300,"elapsed":1143,"user":{"displayName":"Logan Nye","userId":"10840817294754419157"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import numpy as np\n","from PIL import Image\n","import zipfile\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import models\n","\n","data_path = '/content/Enchondroma vs Grade I Chondrosarcoma.v2i.folder'\n","\n","# Define the patch size\n","# Patch size is a hyperparameter that can be tuned! Try 16x16, 32x32, 64x64, 128x128, and 256x256\n","patch_size = (64, 64)\n","\n","# Create a numpy array to store the patches and labels\n","patches = np.empty((0, patch_size[0], patch_size[1], 3))\n","labels = []\n","\n","# Loop through the subfolders in the dataset\n","for subfolder in os.listdir(data_path):\n","    # Get the path to the subfolder\n","    subfolder_path = os.path.join(data_path, subfolder)\n","    # Loop through the images in the subfolder\n","    for filename in os.listdir(subfolder_path):\n","        # Get the path to the image\n","        image_path = os.path.join(subfolder_path, filename)\n","        # Open the image\n","        with Image.open(image_path) as image:\n","            # Get the image width and height\n","            width, height = image.size\n","            # Loop through the patches in the image\n","            for i in range(0, width, patch_size[0]):\n","                for j in range(0, height, patch_size[1]):\n","                    # Crop the patch from the image\n","                    patch = image.crop((i, j, i + patch_size[0], j + patch_size[1]))\n","                    # Convert the patch to a numpy array\n","                    patch = np.array(patch)\n","                    # Add the patch and label to the numpy array\n","                    patches = np.concatenate((patches, patch[np.newaxis]), axis=0)\n","                    labels.append(subfolder)\n","\n","# Normalize the pixel values\n","patches = patches.astype('float32') / 255.\n","\n","# Convert the labels to one-hot encoded format\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(labels)\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","labels = onehot_encoder.fit_transform(integer_encoded)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(patches, labels, test_size=0.2, random_state=42)\n","\n","# Define the dataset and dataloader\n","train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n","train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n","\n","# Define the device for training\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define the model architecture\n","model = models.vision.resnet18(pretrained=True)\n","# Move the model to the device\n","model = model.to(device)\n","model.fc = torch.nn.Linear(512, 2)\n","model.train()\n","\n","# Define the loss function and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","\n","# Define the number of epochs\n","num_epochs = 20\n","\n","# Start the training loop\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_dataloader):\n","        # Move the data to the device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print the loss for this epoch\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# Test the model\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print(f'Accuracy of the model on the test images: {100 * correct / total} %')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"SfcJ7uxTzGpJ","executionInfo":{"status":"error","timestamp":1674163811880,"user_tz":300,"elapsed":1376335,"user":{"displayName":"Logan Nye","userId":"10840817294754419157"}},"outputId":"c172a39b-e71d-4a1c-aa29-8d471bcb76ff"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-52ef99c56ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;31m# Add the patch and label to the numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6QfWKyZ_hoT"},"outputs":[],"source":["import os\n","import numpy as np\n","from PIL import Image\n","import zipfile\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import models\n","\n","data_path = '/content/drive/MyDrive/FARIL-SORG/generated-variations-cartilaginous-tumors'\n","\n","# Define the patch size\n","# Patch size is a hyperparameter that can be tuned! Try 16x16, 32x32, 64x64, 128x128, and 256x256\n","patch_size = (64, 64)\n","\n","# Create a numpy array to store the patches and labels\n","patches = np.empty((0, patch_size[0], patch_size[1], 3))\n","labels = []\n","\n","# Loop through the subfolders in the dataset\n","for subfolder in os.listdir(data_path):\n","    # Get the path to the subfolder\n","    subfolder_path = os.path.join(data_path, subfolder)\n","    # Loop through the images in the subfolder\n","    for filename in os.listdir(subfolder_path):\n","        # Get the path to the image\n","        image_path = os.path.join(subfolder_path, filename)\n","        # Open the image\n","        with Image.open(image_path) as image:\n","            # Get the image width and height\n","            width, height = image.size\n","            # Loop through the patches in the image\n","            for i in range(0, width, patch_size[0]):\n","                for j in range(0, height, patch_size[1]):\n","                    # Crop the patch from the image\n","                    patch = image.crop((i, j, i + patch_size[0], j + patch_size[1]))\n","                    # Convert the patch to a numpy array\n","                    patch = np.array(patch)\n","                    # Add the patch and label to the numpy array\n","                    patches = np.concatenate((patches, patch[np.newaxis]), axis=0)\n","                    labels.append(subfolder)\n","\n","    # Normalize the pixel values\n","    patches = patches.astype('float32') / 255.\n","\n","    # Convert the labels to one-hot encoded format\n","    label_encoder = LabelEncoder()\n","    integer_encoded = label_encoder.fit_transform(labels)\n","    onehot_encoder = OneHotEncoder(sparse=False)\n","    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n","    labels = onehot_encoder.fit_transform(integer_encoded)\n","\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(patches, labels, test_size=0.2, random_state=42)\n","    # Define the dataset and dataloader\n","    train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n","    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","    test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n","    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n","\n","    # Define the device for training\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Define the model architecture\n","    model = models.vision.resnet18(pretrained=True)\n","    # Move the model to the device\n","    model = model.to(device)\n","    model.fc = torch.nn.Linear(512, 2)\n","    model.train()\n","\n","    # Define the loss function and optimizer\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","    # Train the model\n","    num_epochs = 10\n","    for epoch in range(num_epochs):\n","        for i, (images, labels) in enumerate(train_dataloader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(images)\n","            loss = criterion(outputs, labels.argmax(1))\n","\n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","    # Test the model\n","    model.eval()\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in test_dataloader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels.argmax(1)).sum().item()\n","\n","        print(f'Test Accuracy of the model on the test images: {correct / total}')\n","\n"]},{"cell_type":"markdown","source":["In this script, we are training the model for a specified number of epochs using the training data with the defined loss function and optimizer. After each epoch, we are evaluating the model's performance on the test data by comparing the predicted labels to the actual labels. We are calculating the accuracy of the model:"],"metadata":{"id":"BoCfP4EjHR8G"}},{"cell_type":"code","source":["# Define the number of training epochs\n","num_epochs = 100\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    for inputs, labels in train_dataloader:\n","        # Move the data to the GPU, if available\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print the loss every 10 epochs\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# Evaluate the model on the test dataset\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for inputs, labels in test_dataloader:\n","        # Move the data to the GPU, if available\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        # Count the number of correct predictions\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    # Print the accuracy\n","    print(f'Accuracy of the model on the test dataset: {100 * correct / total:.2f}%')\n"],"metadata":{"id":"CIurKnZbFYWT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After loading and preprocessing the image data, the next step would be to train the Vision Transformer (ViT) model on the training data. Once the model is trained, we can evaluate its performance on the test data. Here is the script for the next steps:"],"metadata":{"id":"nDD1FefAHDfT"}},{"cell_type":"code","source":["# Define the device for training\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Move the model to the device\n","model = model.to(device)\n","\n","# Define the number of training epochs\n","num_epochs = 100\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    for inputs, labels in train_dataloader:\n","        # Move the data to the GPU, if available\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Print the loss every 10 epochs\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","# Evaluate the model on the test data\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for inputs, labels in test_dataloader:\n","        # Move the data to the GPU, if available\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    # Print the test accuracy\n","    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"],"metadata":{"id":"RXtQdfrPG_4m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To understand why the ViT binary classifier model is making certain predictions, you can use the technique of saliency maps or class activation maps (CAMs). These methods generate heatmaps that highlight the regions of the input image that the model is focusing on when making a prediction. Here is an example of how to generate a CAM for the ViT binary classifier model using the \"Grad-CAM\" method:"],"metadata":{"id":"RBM5UIuJIudE"}},{"cell_type":"code","source":["# Import the necessary libraries\n","from torch.nn import functional as F\n","from torchvision.utils import make_grid, save_image\n","\n","# Define a hook function to extract the feature maps\n","def hook_feature(module, input, output):\n","    features.append(output.cpu().data.numpy())\n","\n","# Register the hook function to the last convolutional layer\n","handle = model.final_layer.register_forward_hook(hook_feature)\n","\n","# Initialize an empty list to store the feature maps\n","features = []\n","\n","# Get the input image and label\n","inputs, labels = next(iter(test_dataloader))\n","inputs = inputs.to(device)\n","\n","# Forward pass\n","model(inputs)\n","\n","# Remove the hook function\n","handle.remove()\n","\n","# Get the feature maps and the last convolutional layer's weight\n","feature_maps = features[0]\n","weight = model.final_layer.weight.cpu().data.numpy()\n","\n","# Get the class index of the true label\n","class_idx = labels[0].item()\n","\n","# Get the class activation maps\n","cam = np.zeros_like(feature_maps[0])\n","for i, w in enumerate(weight[class_idx]):\n","    cam += w * feature_maps[i]\n","\n","# Normalize the CAM\n","cam = (cam - cam.min()) / (cam.max() - cam.min())\n","\n","# Resize the CAM to the size of the input image\n","cam = cv2.resize(cam, (inputs.shape[3], inputs.shape[2]))\n","\n","# Create a heatmap of the CAM\n","heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n","\n","# Overlay the heatmap on the input image\n","result = heatmap * 0.5 + inputs[0].cpu().numpy().transpose(1, 2, 0)\n","result = result / result.max()\n","\n","# Save the result as an image\n","save_image(torch.from_numpy(result.transpose(2, 0, 1)), 'cam.png')"],"metadata":{"id":"6lAnjA2wIqir"},"execution_count":null,"outputs":[]}]}